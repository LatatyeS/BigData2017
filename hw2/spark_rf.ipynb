{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4j\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel, GradientBoostedTrees\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.regression import *\n",
    "from pyspark.mllib.classification import *\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import types\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[4]\")\n",
    "        .setAppName(\"ML demo\")\n",
    "        .set(\"spark.executor.memory\", \"2g\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionModel, LinearRegressionWithSGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlcontext.read.format(\n",
    "    'com.databricks.spark.csv').options(\n",
    "    header='true').load('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId='1', Survived='0', Pclass='3', Name='Braund, Mr. Owen Harris', Sex='male', Age='22', SibSp='1', Parch='0', Ticket='A/5 21171', Fare='7.25', Cabin=None, Embarked='S'),\n",
       " Row(PassengerId='2', Survived='1', Pclass='1', Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Sex='female', Age='38', SibSp='1', Parch='0', Ticket='PC 17599', Fare='71.2833', Cabin='C85', Embarked='C'),\n",
       " Row(PassengerId='3', Survived='1', Pclass='3', Name='Heikkinen, Miss. Laina', Sex='female', Age='26', SibSp='0', Parch='0', Ticket='STON/O2. 3101282', Fare='7.925', Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age\n",
    "def age_nominal(y):\n",
    "    try:\n",
    "        y = int(y)\n",
    "    except:\n",
    "        return -1\n",
    "    return y // 20\n",
    "\n",
    "udf_age = udf(age_nominal, returnType=IntegerType())\n",
    "df = df.withColumn('age_nominal', udf_age(df['Age']))\n",
    "# add onehot \n",
    "str_ind = StringIndexer(inputCol=\"age_nominal\", outputCol=\"age_nominal_ind\")\n",
    "model = str_ind.fit(df)\n",
    "ind = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"age_nominal_ind\", outputCol=\"age_nominal_map\")\n",
    "df = encoder.transform(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fare\n",
    "def fare_nominal(p):\n",
    "    try:\n",
    "        p = float(p)\n",
    "    except:\n",
    "        return -1\n",
    "    return int(p // 5)\n",
    "\n",
    "udf_price = udf(fare_nominal, returnType=IntegerType())\n",
    "df = df.withColumn('fare_nominal', udf_price(df['Fare']))\n",
    "# add onehot \n",
    "str_ind = StringIndexer(inputCol=\"fare_nominal\", outputCol=\"fare_nominal_ind\")\n",
    "model = str_ind.fit(df)\n",
    "ind = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"fare_nominal_ind\", outputCol=\"fare_nominal_map\")\n",
    "df = encoder.transform(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alone\n",
    "def not_alone(sibsp, parch):\n",
    "    return 0 if int(sibsp) + int(parch) == 0 else 1\n",
    "udf_alone = udf(not_alone, returnType=IntegerType())\n",
    "df = df.withColumn('not_alone', udf_alone(df['Sibsp'], df['Parch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##encode pclass\n",
    "\n",
    "str_ind = StringIndexer(inputCol=\"Pclass\", outputCol=\"Pclass_ind\")\n",
    "model = str_ind.fit(df)\n",
    "ind = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"Pclass_ind\", outputCol=\"Pclass_map\")\n",
    "df = encoder.transform(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='Q'), Row(Embarked='C'), Row(Embarked='S'), Row(Embarked='')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def Embarked_transform(x):\n",
    "    if x != None:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "my_udf = udf(Embarked_transform, types.StringType())\n",
    "df = df.withColumn('Embarked', my_udf(df['Embarked']))\n",
    "df.select('Embarked').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "df_t = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string, age_nominal: int, age_nominal_ind: double, age_nominal_map: vector, fare_nominal: int, fare_nominal_ind: double, fare_nominal_map: vector, not_alone: int, EmbarkedIndex: double, EmbarkedVec: vector]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_age(str_age):\n",
    "    try:\n",
    "        return float(str_age)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transf(r):\n",
    "    return LabeledPoint(\n",
    "        int(r.Survived),\n",
    "        [\n",
    "            int(r.Pclass),\n",
    "            r.Sex == 'male',\n",
    "            float(r.Fare),\n",
    "            int(r.SibSp),\n",
    "            int(r.Parch),\n",
    "            parse_age(r.Age),\n",
    "        ] + list(r.EmbarkedVec.toArray())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df_t.rdd.map(transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[140] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "rfc = RandomForest.trainClassifier(train, numClasses=2,\n",
    "                             categoricalFeaturesInfo={},\n",
    "                            numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(m, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = rfc.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    errors = comp.map(lambda x: np.absolute(x[0]-x[1]))\n",
    "    return 1-errors.sum()/errors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82229965156794427"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f1 metric\n",
    "def f1(model, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = model.predict(values)\n",
    "    yhat = yhat.map(lambda x: float(x))\n",
    "    y = test.map(lambda x: float(x.label))\n",
    "    predictions_and_labels = yhat.zip(y)\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    f1Score = metrics.fMeasure()\n",
    "    \n",
    "    return f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.latatye/anaconda3/lib/python3.6/site-packages/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8222996515679443"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(rfc,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.latatye/anaconda3/lib/python3.6/site-packages/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    }
   ],
   "source": [
    "rfc = LogisticRegressionWithSGD.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.latatye/anaconda3/lib/python3.6/site-packages/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.61672473867595823, 0.6167247386759582)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test), f1(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = LogisticRegressionWithLBFGS.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.latatye/anaconda3/lib/python3.6/site-packages/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.80836236933797911, 0.8083623693379791)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test), f1(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = GradientBoostedTrees.trainClassifier(train,\n",
    "                                           categoricalFeaturesInfo={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.latatye/anaconda3/lib/python3.6/site-packages/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.83275261324041816, 0.8327526132404182)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test), f1(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# добавить 5 новых фичей\n",
    "# 3 фичи высчитываются из имеющихся\n",
    "# хотя бы одна использует udf\n",
    "\n",
    "# попробовать 3 новых модели\n",
    "\n",
    "# f1 меру"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
